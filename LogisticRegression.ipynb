{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRIz1TE2uF1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627f24ad-ea59-473d-9c02-042da2fb3c20"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from platform import python_version\n",
        "print (python_version())\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.10\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdWf7kKR00ce",
        "outputId": "9f3b0c8b-d3cd-4323-80a2-815367cb4488"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "\n",
        "df = pd.read_csv(\"/content/tweets.xls\")\n",
        "split_percent = 0.7\n",
        "df_length = int(len(df)*split_percent)\n",
        "train_df = df.iloc[:df_length,:]\n",
        "test_df = df.iloc[df_length:,:]\n",
        "train_df.to_csv(\"train.csv\")\n",
        "test_df.to_csv(\"test.csv\")\n",
        "\n",
        "print(len(train_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7958\n",
            "3412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYxZli3nuF17"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOroTQnjuF1-"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "    words = [w for w in text if w not in stopwords.words('english')]\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzhxvbjUuF2A"
      },
      "source": [
        "def pre_process_text_combined(text):\n",
        "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "    cleaned_txt = clean_text(text)\n",
        "    tokenized_text = tokenizer.tokenize(cleaned_txt)\n",
        "    remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
        "    combined_text = ' '.join(remove_stopwords)\n",
        "    return  combined_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZp_T4a-uF2B"
      },
      "source": [
        "train_df2=train_df.copy()\n",
        "train_df2['text'] = train_df2['text'].apply(lambda x : pre_process_text_combined(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5UaxWBcuF2B"
      },
      "source": [
        "test_df2=test_df.copy()\n",
        "test_df2['text'] = test_df2['text'].apply(lambda x : pre_process_text_combined(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhdgv5efuF2D"
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "train_cv = count_vectorizer.fit_transform(train_df2['text'])\n",
        "test_cv = count_vectorizer.transform(test_df2[\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk7WgU_CuF2D"
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
        "train_tf = tfidf.fit_transform(train_df2['text'])\n",
        "test_tf = tfidf.transform(test_df2[\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUKyKq-GuF2D"
      },
      "source": [
        "X_train_cv, X_test_cv, y_train_cv, y_test_cv =train_test_split(train_cv,train_df.target,test_size=0.2,random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqeWn895uF2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cea3ec6-3990-4c41-884a-4f69e3d24ce7"
      },
      "source": [
        "# Fitting 'LogisticRegression()' with CountVectorizer() fit dataset\n",
        "clf_logreg = LogisticRegression(C=1.0)\n",
        "clf_logreg.fit(X_train_cv, y_train_cv)\n",
        "pred=clf_logreg.predict(X_test_cv)\n",
        "confusion_matrix(y_test_cv,pred)\n",
        "print(classification_report(y_test_cv,pred))\n",
        "print('Accuracy of classifier on training set:{}%'.format(round(clf_logreg.score(X_train_cv, y_train_cv)*100)))\n",
        "print('Accuracy of classifier on test set:{}%' .format(round(accuracy_score(y_test_cv,pred)*100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      1313\n",
            "           1       0.88      0.52      0.66       279\n",
            "\n",
            "    accuracy                           0.90      1592\n",
            "   macro avg       0.89      0.75      0.80      1592\n",
            "weighted avg       0.90      0.90      0.89      1592\n",
            "\n",
            "Accuracy of classifier on training set:98%\n",
            "Accuracy of classifier on test set:90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVFkPia0WDeN"
      },
      "source": [
        "# Tempo di esecuzione\n",
        "print(datetime.now() - now)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}